{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquiring and Processing Information on the World's Largest Banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been hired as a data engineer by research organization. Your boss has asked you to create a code that can be used to compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD. Further, the data needs to be transformed and stored in USD, GBP, EUR and INR as well, in accordance with the exchange rate information that has been made available to you as a CSV file. The processed information table is to be saved locally in a CSV format and as a database table.\n",
    "\n",
    "Your job is to create an automated system to generate this information so that the same can be executed in every financial quarter to prepare the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project libraries have been imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries for web scraping and data manipulation\n",
    "import requests\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "print(\"Project libraries have been imported successfully\")\n",
    "\n",
    "# Store final output data and all logs\n",
    "log_file = \"code_log.txt\"\n",
    "target_file = \"Largest_banks_data.csv\"\n",
    "\n",
    "# Initialize all known entities\n",
    "data_url = 'https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "csv_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
    "table_attribs = [\"Name\", \"MC_USD_Billions\"]\n",
    "table_attribs_final = [\"Name\", \"MC_USD_Billion\", \"MC_GBP_Billion\", \"MC_EUR_Billion\", \"MC_INR_Billion\"]\n",
    "\n",
    "db_name = \"Banks.db\"\n",
    "table_name = \"Largest_banks\"\n",
    "csv_path = '~/Documents/IBM-Data-Engineering-Professional/Course 3 - Python Project for Data Engineering/Extract, Transform and Load Market Capitalization data/Largest_banks_data.csv'\n",
    "\n",
    "# # Useful functions for ETL operations on Market capitalization data\n",
    "# # Extraction\n",
    "# def extract(data_url, table_attribs):\n",
    "#     html_page = requests.get(url).text\n",
    "#     data = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "#     # Using find_all() function\n",
    "#     extracted_data = pd.DataFrame(columns = table_attribs)\n",
    "#     tables = data.find_all(\"tbody\")\n",
    "#     rows = tables[2].find_all(\"tr\")\n",
    "#     for row in rows:\n",
    "#         col = row.find_all(\"td\")\n",
    "#         if len(col) != 0: \n",
    "#             if col[0].find('a') is not None and \"—\" not in col[2]:\n",
    "#                 data_dict = {\"Country\": col[0].a.contents[0], \n",
    "#                             \"GDP_USD_millions\": col[2].contents[0]}\n",
    "#                 df1 = pd.DataFrame(data_dict, index=[0])\n",
    "#                 extracted_data = pd.concat([extracted_data, df1], ignore_index = True)\n",
    "#     return extracted_data\n",
    "\n",
    "\n",
    "# # Transformation\n",
    "# def transform(df): \n",
    "#     ''' This function converts the GDP information from Currency\n",
    "#     format to float value, transforms the information of GDP from\n",
    "#     USD (Millions) to USD (Billions) rounding to 2 decimal places.\n",
    "#     The function returns the transformed dataframe.'''\n",
    "#     estimate = df[\"GDP_USD_millions\"].values.tolist()\n",
    "#     estimate = [round(int(i.replace(',', '')) / 1000, 2) for i in estimate]\n",
    "#     df_estimate = pd.DataFrame(estimate, columns=['GDP_USD_billions'])\n",
    "#     df = df.join(df_estimate)\n",
    "#     return df[[\"Country\", \"GDP_USD_billions\"]] \n",
    "\n",
    "# # Loading and Logging\n",
    "# def load_to_csv(df, csv_path):\n",
    "#     ''' This function saves the final dataframe as a `CSV` file \n",
    "#     in the provided path. Function returns nothing.'''\n",
    "#     df.to_csv(csv_path)\n",
    "\n",
    "# def load_to_db(df, sql_connection, table_name):\n",
    "#     ''' This function saves the final dataframe as a database table\n",
    "#     with the provided name. Function returns nothing.'''\n",
    "#     df.to_sql(table_name, sql_connection, if_exists= \"replace\", index = False)\n",
    "    \n",
    "# def run_query(query_statement, sql_connection):\n",
    "#     ''' This function runs the stated query on the database table and\n",
    "#     prints the output on the terminal. Function returns nothing. '''\n",
    "#     print(query_statement)\n",
    "#     return pd.read_sql(query_statement, sql_connection)\n",
    "    \n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message at a given stage of the code execution to a log file. Function returns nothing'''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(\"./code_log.txt\", \"a\") as f: \n",
    "        f.write(timestamp + ', ' + message + '\\n')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "              Country  GDP_USD_billions\n",
      "0       United States          26854.60\n",
      "1               China          19373.59\n",
      "2               Japan           4409.74\n",
      "3             Germany           4308.85\n",
      "4               India           3736.88\n",
      "..                ...               ...\n",
      "186  Marshall Islands              0.29\n",
      "187             Palau              0.26\n",
      "188          Kiribati              0.25\n",
      "189             Nauru              0.15\n",
      "190            Tuvalu              0.07\n",
      "\n",
      "[191 rows x 2 columns]\n",
      "SELECT * FROM Countries_by_GDP WHERE GDP_USD_billions >= 100\n",
      "          Country  GDP_USD_billions\n",
      "0   United States          26854.60\n",
      "1           China          19373.59\n",
      "2           Japan           4409.74\n",
      "3         Germany           4308.85\n",
      "4           India           3736.88\n",
      "..            ...               ...\n",
      "64          Kenya            118.13\n",
      "65         Angola            117.88\n",
      "66           Oman            104.90\n",
      "67      Guatemala            102.31\n",
      "68       Bulgaria            100.64\n",
      "\n",
      "[69 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Testing ETL operations and log progress\n",
    "# Log the initialization of the ETL process \n",
    "log_progress(\"Preliminaries complete. Initiating ETL process\")\n",
    "extracted_data = extract(url, table_attribs)\n",
    " \n",
    "# Log the completion of the Extraction process and begin transformation process\n",
    "log_progress(\"Data extraction complete. Initiating Transformation process\")\n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process and begin loading process\n",
    "log_progress(\"Data transformation complete. Initiating loading process\")\n",
    "load_to_csv(transformed_data, csv_path)\n",
    "\n",
    "log_progress(\"Data saved to CSV file\") \n",
    "\n",
    "# Use SQLite3 to create and connect to a new database World_Economies.db\n",
    "sql_connection = sqlite3.connect(db_name)\n",
    "\n",
    "log_progress(\"SQL Connection initiated\")\n",
    "\n",
    "load_to_db(transformed_data, sql_connection, table_name)\n",
    "\n",
    "log_progress(\"Data loaded to Database as table. Running the query\")\n",
    "\n",
    "query_statement = f\"SELECT * FROM {table_name} WHERE GDP_USD_billions >= 100\"\n",
    "print(run_query(query_statement, sql_connection))\n",
    " \n",
    "# Log the completion of the process \n",
    "log_progress(\"Process Complete\") \n",
    "\n",
    "sql_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(data_url, table_attribs):\n",
    "    html_page = requests.get(url).text\n",
    "    data = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    # Using find_all() function\n",
    "    extracted_data = pd.DataFrame(columns = table_attribs)\n",
    "    tables = data.find_all(\"tbody\")\n",
    "    rows = tables[2].find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        col = row.find_all(\"td\")\n",
    "        if len(col) != 0: \n",
    "            if col[0].find('a') is not None and \"—\" not in col[2]:\n",
    "                data_dict = {\"Country\": col[0].a.contents[0], \n",
    "                            \"GDP_USD_millions\": col[2].contents[0]}\n",
    "                df1 = pd.DataFrame(data_dict, index=[0])\n",
    "                extracted_data = pd.concat([extracted_data, df1], ignore_index = True)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name MC_USD_Billions\n",
      "0                           JPMorgan Chase        419.25\\n\n",
      "1                          Bank of America        231.52\\n\n",
      "2  Industrial and Commercial Bank of China        194.56\\n\n",
      "3               Agricultural Bank of China        160.68\\n\n",
      "4                                HDFC Bank        157.91\\n\n",
      "5                              Wells Fargo        155.87\\n\n",
      "6                        HSBC Holdings PLC        148.90\\n\n",
      "7                           Morgan Stanley        140.83\\n\n",
      "8                  China Construction Bank        139.82\\n\n",
      "9                            Bank of China        136.81\\n\n"
     ]
    }
   ],
   "source": [
    "html_page = requests.get(data_url).text\n",
    "data = BeautifulSoup(html_page, 'html.parser')\n",
    "# Using find_all() function\n",
    "extracted_data = pd.DataFrame(columns = table_attribs)\n",
    "tables = data.find_all(\"tbody\")\n",
    "rows = tables[0].find_all(\"tr\")\n",
    "for row in rows:\n",
    "    col = row.find_all(\"td\")\n",
    "    if len(col) != 0:\n",
    "        data_dict = {\"Name\": col[1].contents[2].contents,\n",
    "                    \"MC_USD_Billions\": col[2].contents[0]}\n",
    "        df1 = pd.DataFrame(data_dict, index = [0])\n",
    "        extracted_data = pd.concat([extracted_data, df1], ignore_index = True)\n",
    "print(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
